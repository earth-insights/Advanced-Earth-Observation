# Advanced Pretraining

## Supervised Learning

- SatlasPretrain: A Large-Scale Dataset for Remote Sensing Image Understanding. ICCV'2023. [[Paper](https://arxiv.org/abs/2211.15660) | [Code](https://github.com/allenai/satlas)]
- MTP: Advancing Remote Sensing Foundation Model via Multi-Task Pretraining. JSTARS'2024. [[Paper](https://arxiv.org/abs/2403.13430) | [Code](https://github.com/ViTAE-Transformer/MTP)]
- HyperFree: A Channel-adaptive and Tuning-free Foundation Model for Hyperspectral Remote Sensing Imagery. CVPR'2025. [[Paper](https://openaccess.thecvf.com/content/CVPR2025/html/Li_HyperFree_A_Channel-adaptive_and_Tuning-free_Foundation_Model_for_Hyperspectral_Remote_CVPR_2025_paper.html) | [Code](https://github.com/Jingtao-Li-CVer/HyperFree)]
- MoSAiC: Multi-Modal Multi-Label Supervision-Aware Contrastive Learning for Remote Sensing. arXiv'2025. [[Paper](https://arxiv.org/abs/2507.08683)]

## Image Contrastive Learning

- Self-Supervised Learning of Remote Sensing Scene Representations Using Contrastive Multiview Coding. CVPRW'2021. [[Paper](https://openaccess.thecvf.com/content/CVPR2021W/EarthVision/html/Stojnic_Self-Supervised_Learning_of_Remote_Sensing_Scene_Representations_Using_Contrastive_Multiview_CVPRW_2021_paper.html) | [Code](https://github.com/vladan-stojnic/CMC-RSSR)]
- Geography-Aware Self-Supervised Learning. ICCV'2021. [[Paper](https://openaccess.thecvf.com/content/ICCV2021/html/Ayush_Geography-Aware_Self-Supervised_Learning_ICCV_2021_paper.html) | [Code](https://github.com/sustainlab-group/geography-aware-ssl)]
- Seasonal Contrast: Unsupervised Pre-Training From Uncurated Remote Sensing Data. ICCV'2021. [[Paper](https://openaccess.thecvf.com/content/ICCV2021/html/Manas_Seasonal_Contrast_Unsupervised_Pre-Training_From_Uncurated_Remote_Sensing_Data_ICCV_2021_paper.html) | [Code](https://github.com/ServiceNow/seasonal-contrast)]
- Self-supervised Vision Transformers for Joint SAR-optical Representation Learning. IGARSS'2022. [[Paper](https://arxiv.org/abs/2204.05381) | [Code](https://github.com/zhu-xlab/DINO-MM)]
- Self-Supervised Material and Texture Representation Learning for Remote Sensing Tasks. CVPR'2022. [[Paper](https://openaccess.thecvf.com/content/CVPR2022/html/Akiva_Self-Supervised_Material_and_Texture_Representation_Learning_for_Remote_Sensing_Tasks_CVPR_2022_paper.html)]
- Self-supervised Vision Transformers for Land-cover Segmentation and Classification. CVPRW'2022. [[Paper](https://openaccess.thecvf.com/content/CVPR2022W/EarthVision/html/Scheibenreif_Self-Supervised_Vision_Transformers_for_Land-Cover_Segmentation_and_Classification_CVPRW_2022_paper.html) | [Code](https://github.com/HSG-AIML/SSLTransformerRS)]
- CMID: A Unified Self-Supervised Learning Framework for Remote Sensing Image Understanding. TGRS'2023. [[Paper](https://arxiv.org/abs/2304.09670) | [Code](https://github.com/NJU-LHRS/official-CMID)]
- Multi-Modal Multi-Objective Contrastive Learning for Sentinel-1/2 Imagery. CVPRW'2023. [[Paper](https://openaccess.thecvf.com/content/CVPR2023W/EarthVision/html/Prexl_Multi-Modal_Multi-Objective_Contrastive_Learning_for_Sentinel-12_Imagery_CVPRW_2023_paper.html)]
- Change-Aware Sampling and Contrastive Learning for Satellite Images. CVPR'2023. [[Paper](https://openaccess.thecvf.com/content/CVPR2023/html/Mall_Change-Aware_Sampling_and_Contrastive_Learning_for_Satellite_Images_CVPR_2023_paper.html) | [Code](https://github.com/utkarshmall13/CACo)]
- Towards Geospatial Foundation Models via Continual Pretraining. ICCV'2023. [[Paper](https://arxiv.org/abs/2302.04476) | [Code](https://github.com/mmendiet/GFM)]
- CROMA: Remote Sensing Representations with Contrastive Radar-Optical Masked Autoencoders. NeurIPS'23. [[Paper](https://arxiv.org/pdf/2311.00566.pdf) | [Code](https://github.com/antofuller/CROMA)]
- Cross-Scale MAE: A Tale of Multiscale Exploitation in Remote Sensing. NeurIPS'23. [[Paper](https://openreview.net/pdf?id=5oEVdOd6TV) | [Code](https://github.com/aicip/Cross-Scale-MAE)]
- Extending global-local view alignment for self-supervised learning with remote sensing imagery. CVPRW'2024. [[Paper](https://openaccess.thecvf.com/content/CVPR2024W/WiCV/html/Wanyan_Extending_Global-local_View_Alignment_for_Self-supervised_Learning_with_Remote_Sensing_CVPRW_2024_paper.html) | [Code](https://github.com/WennyXY/DINO-MC)]
- SkySense: A Multi-Modal Remote Sensing Foundation Model Towards Universal Interpretation for Earth Observation Imagery. CVPR'2024. [[Paper](https://arxiv.org/abs/2312.10115)]
- Panopticon: Advancing Any-Sensor Foundation Models for Earth Observation. arXiv'2025. [[Paper](https://www.arxiv.org/abs/2503.10845) | [Code](https://github.com/Panopticon-FM/panopticon)]
- Towards Privacy-preserved Pre-training of Remote Sensing Foundation Models with Federated Mutual-guidance Learning. ICCV'2025. [[Paper](https://arxiv.org/abs/2503.11051)]
- RS-vHeat: Heat Conduction Guided Efficient Remote Sensing Foundation Model. ICCV'2025. [[Paper](https://arxiv.org/abs/2411.17984)]
- CGEarthEye: A High-Resolution Remote Sensing Vision Foundation Model Based on the Jilin-1 Satellite Constellation. arXiv'2025. [[Paper](https://arxiv.org/abs/2507.00356)]

## Masked Image Modeling

- SatMAE: Pre-training Transformers for Temporal and Multi-Spectral Satellite Imagery. NeurIPS'2022. [[Paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/01c561df365429f33fcd7a7faa44c985-Abstract-Conference.html) | [Code](https://github.com/sustainlab-group/SatMAE)]
- RingMo: A remote sensing foundation model with masked image modeling. TGRS'2022. [[Paper](https://ieeexplore.ieee.org/abstract/document/9844015) | [Code](https://github.com/comeony/RingMo)]
- Advancing plain vision transformer toward remote sensing foundation model. TGRS'2022. [[Paper](https://ieeexplore.ieee.org/abstract/document/9956816) | [Code](https://github.com/ViTAE-Transformer/Remote-Sensing-RVSA)]
- CMID: A Unified Self-Supervised Learning Framework for Remote Sensing Image Understanding. TGRS'2023. [[Paper](https://arxiv.org/abs/2304.09670) | [Code](https://github.com/NJU-LHRS/official-CMID)]
- A Billion-scale Foundation Model for Remote Sensing Images. arXiv'2023. [[Paper](https://arxiv.org/abs/2304.05215)]
- Towards Geospatial Foundation Models via Continual Pretraining. ICCV'2023. [[Paper](https://arxiv.org/abs/2302.04476) | [Code](https://github.com/mmendiet/GFM)]
- Scale-MAE: A Scale-Aware Masked Autoencoder for Multiscale Geospatial Representation Learning. ICCV'2023. [[Paper](https://arxiv.org/abs/2212.14532) | [Code](https://github.com/bair-climate-initiative/scale-mae)]
- CROMA: Remote Sensing Representations with Contrastive Radar-Optical Masked Autoencoders. NeurIPS'23. [[Paper](https://arxiv.org/pdf/2311.00566) | [Code](https://github.com/antofuller/CROMA)]
- Cross-Scale MAE: A Tale of Multiscale Exploitation in Remote Sensing. NeurIPS'23. [[Paper](https://openreview.net/pdf?id=5oEVdOd6TV) | [Code](https://github.com/aicip/Cross-Scale-MAE)]
- Foundation Models for Generalist Geospatial Artificial Intelligence. CVPR'2023. [[Paper](https://arxiv.org/abs/2310.18660) | [Code](https://huggingface.co/ibm-nasa-geospatial)]
- Masked vision transformers for hyperspectral image classification. CVPRW'2023. [[Paper](https://openaccess.thecvf.com/content/CVPR2023W/EarthVision/html/Scheibenreif_Masked_Vision_Transformers_for_Hyperspectral_Image_Classification_CVPRW_2023_paper.html) | [Code](https://github.com/HSG-AIML/MaskedSST)]
- USat: A Unified Self-Supervised Encoder for Multi-Sensor Satellite Imagery. arXiv'2023. [[Paper](https://arxiv.org/abs/2312.02199) | [Code](https://github.com/stanfordmlgroup/USat)]
- SpectralGPT: Spectral Remote Sensing Foundation Model. TPAMI'2024. [[Paper](https://arxiv.org/abs/2311.07113) | [Code](https://github.com/danfenghong/IEEE_TPAMI_SpectralGPT)]
- S2MAE: A Spatial-Spectral Pretraining Foundation Model for Spectral Remote Sensing Data. CVPR'2024. [[Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Li_S2MAE_A_Spatial-Spectral_Pretraining_Foundation_Model_for_Spectral_Remote_Sensing_CVPR_2024_paper.pdf)]
- Rethinking Transformers Pre-training for Multi-Spectral Satellite Imagery. CVPR'2024. [[Paper](https://arxiv.org/abs/2403.05419) | [Code](https://github.com/techmn/satmae_pp)]
- Bridging Remote Sensors with Multisensor Geospatial Foundation Models. CVPR'2024. [[Paper](https://arxiv.org/abs/2404.01260) | [Code](https://github.com/boranhan/Geospatial_Foundation_Models)]
- MMEarth: Exploring Multi-Modal Pretext Tasks For Geospatial Representation Learning. ECCV'2024. [[Paper](https://arxiv.org/abs/2405.02771) | [Code](https://vishalned.github.io/mmearth/)]
- Neural Plasticity-Inspired Foundation Model for Observing the {Earth} Crossing Modalities. arXiv'2024. [[Paper](https://arxiv.org/abs/2403.15356) | [Code](https://github.com/zhu-xlab/DOFA)]
- SenPa-MAE: Sensor Parameter Aware Masked Autoencoder for Multi-Satellite Self-Supervised Pretraining. arXiv'2024. [[Paper](https://arxiv.org/abs/2408.11000) | [Code](https://github.com/JonathanPrexl/SenPa-MAE)]
- OmniSat: Self-Supervised Modality Fusion for Earth Observation. ECCV'2024. [[Paper](https://arxiv.org/pdf/2404.08351) | [Code](https://github.com/gastruc/OmniSat)]
- Masked Angle-Aware Autoencoder for Remote Sensing Images.  ECCV'2024. [[Paper](https://arxiv.org/abs/2408.01946) | [Code](https://github.com/benesakitam/MA3E)]
- Predicting Gradient is Better: Exploring Self-Supervised Learning for SAR ATR with a Joint-Embedding Predictive Architecture. ISPRS JP&RS'2024. [[Paper](https://www.sciencedirect.com/science/article/pii/S0924271624003514) | [Code](https://github.com/waterdisappear/SAR-JEPA)]
- OReole-FM: successes and challenges toward billion-parameter foundation models for high-resolution satellite imagery. SIGSPATIAL'2024. [[Paper](https://arxiv.org/abs/2410.19965)]
- AnySat: An Earth Observation Model for Any Resolutions, Scales, and Modalities. arXiv'2024. [[Paper](https://arxiv.org/abs/2412.14123) | [Code](https://github.com/gastruc/AnySat)]
- Prithvi-EO-2.0: A Versatile Multi-Temporal Foundation Model for Earth Observation Applications. arXiv'2024. [[Paper](https://arxiv.org/abs/2412.02732) | [Code](https://github.com/NASA-IMPACT/Prithvi-EO-2.0)]
- HyperSIGMA: Hyperspectral Intelligence Comprehension Foundation Model. TPAMI'2025. [[Paper](https://arxiv.org/abs/2406.11519) | [Code](https://github.com/WHU-Sigma/HyperSIGMA)]
- FoMo: Multi-Modal, Multi-Scale and Multi-Task Remote Sensing Foundation Models for Forest Monitoring. AAAI'2025. [[Paper](https://arxiv.org/abs/2312.10114) | [Code](https://github.com/RolnickLab/FoMo-Bench)]
- Harnessing Massive Satellite Imagery with Efficient Masked Image Modeling. ICCV'2025. [[Paper](https://arxiv.org/abs/2406.11933) | [Code](https://github.com/MiliLab/SelectiveMAE)]
- Galileo: Learning Global & Local Features of Many Remote Sensing Modalities. arXiv'2025. [[Paper](https://arxiv.org/abs/2502.09356) | [Code](https://github.com/nasaharvest/galileo)]
- Towards a Unified Copernicus Foundation Model for Earth Vision. arXiv'2025. [[Paper](https://arxiv.org/abs/2503.11849) | [Code](https://github.com/zhu-xlab/Copernicus-FM)]
- RoMA: Scaling up Mamba-based Foundation Models for Remote Sensing. arXiv'2025. [[Paper](https://arxiv.org/abs/2503.10392) | [Code](https://github.com/MiliLab/RoMA)]
- Towards Privacy-preserved Pre-training of Remote Sensing Foundation Models with Federated Mutual-guidance Learning. ICCV'2025. [[Paper](https://arxiv.org/abs/2503.11051)]
- RS-vHeat: Heat Conduction Guided Efficient Remote Sensing Foundation Model. ICCV'2025. [[Paper](https://arxiv.org/abs/2411.17984)]
- SMARTIES: Spectrum-Aware Multi-Sensor Auto-Encoder for Remote Sensing Images. ICCV'2025. [[Paper](https://arxiv.org/abs/2506.19585) | [Code](https://github.com/gsumbul/SMARTIES)]
- MAPEX: Modality-Aware Pruning of Experts for Remote Sensing Foundation Models. arXiv'2025. [[Paper](https://arxiv.org/abs/2507.07527) | [Code](https://github.com/HSG-AIML/MAPEX)]
- CGEarthEye: A High-Resolution Remote Sensing Vision Foundation Model Based on the Jilin-1 Satellite Constellation. arXiv'2025. [[Paper](https://arxiv.org/abs/2507.00356)]

## Image-Text Contrastive Learning

- RemoteCLIP: A Vision Language Foundation Model for Remote Sensing. TGRS'2024. [[Paper](https://arxiv.org/abs/2306.11029) | [Code](https://github.com/ChenDelong1999/RemoteCLIP)]
- RS5M and GeoRSCLIP: A Large Scale Vision-Language Dataset and A Vision-Language Foundation Model for Remote Sensing. TGRS'2024. [[Paper](https://arxiv.org/abs/2306.11300) | [Code](https://github.com/om-ai-lab/RS5M)]
- SkyScript: A Large and Semantically Diverse Vision-Language Dataset for Remote Sensing. AAAI'2024. [[Paper](https://arxiv.org/abs/2312.12856) | [Code](https://github.com/wangzhecheng/SkyScript)]
- SatCLIP: Global, General-Purpose Location Embeddings with Satellite Imagery. AAAI'2025. [[Paper](https://arxiv.org/abs/2311.17179) | [Code](https://github.com/microsoft/satclip)]
- Text2Earth: Unlocking Text-driven Remote Sensing Image Generation with a Global-Scale Dataset and a Foundation Model. GRSM'2025. [[Paper](https://arxiv.org/abs/2501.00895) | [Code](https://github.com/Chen-Yang-Liu/Git-RSCLIP)]
- LRSCLIP: A Vision-Language Foundation Model for Aligning Remote Sensing Image with Longer Text. arXiv'2025. [[Paper](https://arxiv.org/abs/2503.19311)]

## Generative

- Can Generative Geospatial Diffusion Models Excel as Discriminative Geospatial Foundation Models? arXiv'2025. [[Paper](https://arxiv.org/abs/2503.07890)]

